{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "#print(os.listdir('./data/'))\n",
    "noExamples = len(os.listdir('./data'))\n",
    "data = np.zeros((noExamples,(224*224)+1,1))\n",
    "labels = np.zeros((noExamples,1))\n",
    "for itemId, file in zip(range(0,noExamples),os.listdir('./data')):\n",
    "    with h5py.File('./data/'+file, 'r') as f:\n",
    "        tmpdata = np.array(f['cjdata']['image'])\n",
    "        data[itemId,0:224*224,:] = cv.resize(tmpdata, (224,224)).reshape(224*224,1)\n",
    "        data[itemId,224*224,:] = f['cjdata']['label']\n",
    "        print(itemId)\n",
    "\n",
    "        \n",
    "#20% for Test, 80% for Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3064\n"
     ]
    }
   ],
   "source": [
    "\n",
    "noTrain=int(0.8*noExamples);\n",
    "print(data.shape[0])\n",
    "#Random Splitting of Data\n",
    "train,test,__ = np.vsplit(data[np.random.permutation(data.shape[0])],(noTrain,noExamples))\n",
    "xtrain = data[0:noTrain,0:224*224,:].reshape(noTrain,224,224,1)\n",
    "y_train = data[0:noTrain,224*224,:].reshape(noTrain) \n",
    "y_train = y_train.astype(int)\n",
    "xtest = data[noTrain:noExamples,0:224*224,:].reshape(noExamples-noTrain,224,224,1)\n",
    "y_test = data[noTrain:noExamples,224*224,:].reshape(noExamples-noTrain);\n",
    "y_test = y_test.astype(int)\n",
    "x_train, x_test = xtrain/255, xtest/255\n",
    "\n",
    "#print(xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Splitting\n",
    "#x_train,x_test = data[0:noTrain,:,:,:]/255,data[noTrain:noExamples:,:,:,:]/255\n",
    "#y_train,y_test = labels[0:noTrain], labels[noTrain:noExamples:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2451/2451 [==============================] - 50s 20ms/sample - loss: 0.9087 - accuracy: 0.6932\n",
      "Epoch 2/5\n",
      "2451/2451 [==============================] - 52s 21ms/sample - loss: 0.4247 - accuracy: 0.8221\n",
      "Epoch 3/5\n",
      "2451/2451 [==============================] - 51s 21ms/sample - loss: 0.2256 - accuracy: 0.9208\n",
      "Epoch 4/5\n",
      "2451/2451 [==============================] - 54s 22ms/sample - loss: 0.1719 - accuracy: 0.9421\n",
      "Epoch 5/5\n",
      "2451/2451 [==============================] - 52s 21ms/sample - loss: 0.1241 - accuracy: 0.9580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ca01458ef0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(filters=48,kernel_size=11,strides=(2,2),padding=\"valid\", activation='relu', input_shape=(224,224,1)), \n",
    "  tf.keras.layers.MaxPool2D((2,2),padding=\"valid\"),\n",
    "  tf.keras.layers.Conv2D(filters=128,kernel_size=5,strides=(2,2),padding=\"valid\", activation='relu'), \n",
    "  tf.keras.layers.MaxPool2D((2,2),padding=\"valid\"),\n",
    "  tf.keras.layers.Conv2D(filters=192,kernel_size=3,padding=\"valid\", activation='relu'),    \n",
    "  tf.keras.layers.Conv2D(filters=192,kernel_size=3,padding=\"valid\", activation='relu'),\n",
    "  tf.keras.layers.Conv2D(filters=128,kernel_size=3,padding=\"valid\", activation='relu'),         \n",
    "  tf.keras.layers.MaxPool2D((2,2),padding=\"valid\"),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(2048, activation='tanh'),\n",
    "  tf.keras.layers.Dense(2048, activation='tanh'),\n",
    "  tf.keras.layers.Dense(4, activation=tf.nn.softmax),\n",
    " ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "#print(data[0,200:210,200:210])\n",
    "#plt.imshow(data[0,:,:])\n",
    "#plt.show()\n",
    "#print(data.shape)\n",
    "#print(labels.shape)\n",
    "#print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 4s 6ms/sample - loss: 2.3553 - accuracy: 0.3752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.355336336093859, 0.3752039]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
